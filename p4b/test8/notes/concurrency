CONCURRENCY: AN INTRODUCTION

	thread: a new abstraction for a single running process

	each thread has its own private set of registers it uses for cumputation, and a context switch must take place

	why we use threads: parallelism and avoid blocking program progress due to slow I/O

	threads make life complcated: it is already hard to tell what will run when

	why it gets worse: shared data

	the heart of the problem: uncontrolled scheduling

	key concurrency terms:

		1. critical section: a piece of code that accesses a shared resource, usually a variable or data structure

		2. race condition(data race): arises if multiple threads of execution enter the critical section at roughly the same time; both attempt to update the shared data structure, leading to a surprising outcome

		3. indeterminate: an this problem consists of more race conditions, the output of the program varies from run to run, depending on which threads ran when. the outcome is thus not deterministic

		4. mutual exclusion: doing so guarantees that only a single thread ever enters a critical section, thus avoiding races, and resulting in deterministic program outputs 


INTERLUDE: THREAD API

	thread creation

	thread completion

	locks

	condition variables


LOCKS(codes are in ../homework/learn_threads/lock.c):

	a lock is a variable, to use one, we must declare a lock variable of some kind

	lock variable holds the state of the lock at any instant in time, it is either available(or unlock or free)

	view threads as entities created by the programmer but scheduled by the os, locks yields some of that control back to the programmer 

	how to build a working lock: hardware, os

	evaluating locks:

		1. whether the lock does its basic work: provide mutual exclusion

		2. fairness: does each thread contending for the lock get a fair shot at acquiring it once it is free?

		3. performace

	controlling interrupts

	a failed attempt: just using loads/stores

	building working spin locks with test-and-set

	evaluating spin locks:

		1. it provide mutual exclusion

		2. spin locks can't provide any fairness guarantees

		3. on single cpu: spin locks works badly; on multiple cpus: spin locks works well

	compare-and-swap

	load-linked and store-conditional

	fetch-and-add

	how to avoid spinning: a thread spins will waste an entire time slice doing nothing but checking a value which isn't going to change

		1. a simple approach: just yield

		2. using queues: sleeping instead of spinning


LOCK-BASED CONCURRENT DATA STRUCTURES:

	how to add locks to data structures:

		1. concurrent linked lists

		2. concurrent queues

		3. concurrent hash table


CONDITION VARIABLES:

	in multi-threaded programs, it is often useful for a thread to wait for some condition to become true before proceeding, spinning until condition becomes true is inefficient

	a condition variable is an explicit queue that threads can put themslves on when some state of execution is not as desired

	the producer/consumer (bounded buffer) problem

	covering conditions


SEMAPHORES:

	see the codes "../homework/learn_threads"

	binary semaphores(locks)

	semaphores for ordering

	the producer/consumer(bounded buffer) problem

	reader-writer locks

	the dining philosophers

	how to implement semaphores


COMMON CONCURRENCY PROBLEMS:

	types of bugs: non-deadlock bugs and deadlock bugs

	non-deadlock bugs: atomicity violation and order violation

	deadlock bugs: 

		1. conditions for deadlock: mutual exclusion, hold-and-wait, no preemption, circular wait

		2. prevention circular wait: provide a total ordering or a partical ordering on lock acquisition

		3. prevention hold-and-wait: by first grabbing the lock prevention which is a global prevention lock

		4. prevention no preemption: pthread_mutex_trylock() either grabs the lock and return success or error code indicating the lock is held, this method arise another problem: livelock, and we can add a random delay to avoid livelock

		5. prevention mutual exclusion: instead of acquiring a lock, doing the update, and then releasing it(livelock is still a problem)

		6. deadlock avoidance via scheduling

		7. detect and recover